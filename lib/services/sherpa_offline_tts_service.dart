import 'dart:async';
import 'dart:io';
import 'dart:typed_data';
import 'package:flutter/material.dart';
import 'package:path_provider/path_provider.dart';
import 'package:audioplayers/audioplayers.dart';
import 'package:sherpa_onnx/sherpa_onnx.dart';
import 'model_manager.dart';

/// åŸºäºå®˜æ–¹ sherpa_onnx æ’ä»¶çš„ç¦»çº¿ TTS æœåŠ¡
/// 
/// æ³¨æ„ï¼šéœ€è¦å…ˆè¿è¡Œ `flutter pub get` å®‰è£… sherpa_onnx æ’ä»¶
/// ç„¶åæ ¹æ®å®é™… API è°ƒæ•´ä»£ç 
class SherpaOfflineTTSService {
  bool _isInitialized = false;
  double _currentRate = 1.0;
  VoidCallback? _onComplete;
  Function(String)? _onError;
  Function(int, int)? _onProgress; // è¿›åº¦å›è°ƒ (currentPosition, totalDuration)
  
  Timer? _progressTimer;
  int _currentPosition = 0;
  int _totalDuration = 0;
  String _currentText = '';
  
  final AudioPlayer _audioPlayer = AudioPlayer();
  final ModelManager _modelManager = ModelManager();
  
  // Sherpa-ONNX TTS å¼•æ“
  OfflineTts? _tts;
  
  // æ˜¯å¦å·²åˆå§‹åŒ– bindings
  static bool _bindingsInitialized = false;
  
  // æ¨¡å‹è·¯å¾„
  String? _modelPath;
  String? _modelDir;
  
  // å½“å‰ä½¿ç”¨çš„è¯­éŸ³ç±»å‹
  VoiceType _currentVoiceType = VoiceType.female;

  SherpaOfflineTTSService({VoiceType? voiceType}) {
    if (voiceType != null) {
      _currentVoiceType = voiceType;
      _modelManager.setVoiceType(voiceType);
    }
  }
  
  /// è·å–è¯­éŸ³ç±»å‹åç§°
  String _getVoiceTypeName(VoiceType voiceType) {
    return voiceType == VoiceType.male ? 'ç”·å£°' : 'å¥³å£°';
  }

  /// æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½
  Future<bool> isModelDownloaded({VoiceType? voiceType}) async {
    return await _modelManager.isModelDownloaded(voiceType: voiceType);
  }
  
  /// è®¾ç½®è¯­éŸ³ç±»å‹
  void setVoiceType(VoiceType voiceType) {
    if (_currentVoiceType != voiceType) {
      _currentVoiceType = voiceType;
      _modelManager.setVoiceType(voiceType);
      // å¦‚æœå·²åˆå§‹åŒ–ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–ä»¥åŠ è½½æ–°æ¨¡å‹
      if (_isInitialized) {
        _isInitialized = false;
        _tts?.free();
        _tts = null;
      }
    }
  }
  
  /// è·å–å½“å‰è¯­éŸ³ç±»å‹
  VoiceType get currentVoiceType => _currentVoiceType;

  /// åˆå§‹åŒ–æœåŠ¡
  Future<void> initialize() async {
    if (_isInitialized && _tts != null) return;
    
    try {
      // ç¡®ä¿ ModelManager ä½¿ç”¨å½“å‰è¯­éŸ³ç±»å‹
      _modelManager.setVoiceType(_currentVoiceType);
      
      // æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½
      final isDownloaded = await isModelDownloaded(voiceType: _currentVoiceType);
      if (!isDownloaded) {
        throw Exception('${_getVoiceTypeName(_currentVoiceType)}æ¨¡å‹æœªä¸‹è½½ï¼Œè¯·å…ˆä¸‹è½½æ¨¡å‹');
      }
      
      // è·å–æ¨¡å‹ç›®å½•ï¼ˆä½¿ç”¨å½“å‰è¯­éŸ³ç±»å‹ï¼‰
      final modelDir = await _modelManager.getModelDirectory(voiceType: _currentVoiceType);
      _modelDir = modelDir.path;
      
      // è·å–æ¨¡å‹è·¯å¾„ï¼ˆä½¿ç”¨å½“å‰è¯­éŸ³ç±»å‹ï¼‰
      _modelPath = await _modelManager.getModelFilePath(voiceType: _currentVoiceType);
      if (_modelPath == null) {
        throw Exception('æ— æ³•è·å–æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œè¯·å…ˆä¸‹è½½æ¨¡å‹');
      }
      
      // ä½¿ç”¨å®˜æ–¹æ’ä»¶åˆå§‹åŒ– TTS å¼•æ“
      try {
        // åˆå§‹åŒ– bindingsï¼ˆåªéœ€è¦ä¸€æ¬¡ï¼‰
        if (!_bindingsInitialized) {
          initBindings();
          _bindingsInitialized = true;
          print('âœ… Sherpa-ONNX bindings åˆå§‹åŒ–æˆåŠŸ');
        }
        
        // éªŒè¯æ¨¡å‹è·¯å¾„
        final modelFile = File(_modelPath!);
        if (!await modelFile.exists()) {
          throw Exception('æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: $_modelPath');
        }
        print('ğŸ“ æ¨¡å‹æ–‡ä»¶å­˜åœ¨: $_modelPath');
        print('   æ–‡ä»¶å¤§å°: ${await modelFile.length()} å­—èŠ‚');
        
        // åˆ—å‡ºæ¨¡å‹ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        final modelDirObj = Directory(_modelDir ?? '');
        if (await modelDirObj.exists()) {
          print('ğŸ“‚ æ¨¡å‹ç›®å½•å†…å®¹:');
          await for (final entity in modelDirObj.list()) {
            if (entity is File) {
              final size = await entity.length();
              print('   - ${entity.path.split('/').last} (${size} å­—èŠ‚)');
            } else if (entity is Directory) {
              print('   - ${entity.path.split('/').last}/ (ç›®å½•)');
            }
          }
        }
        
        // è·å–æ¨¡å‹æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•ï¼ˆè¿™æ˜¯å®é™…çš„æ•°æ®ç›®å½•ï¼‰
        // ä¾‹å¦‚ï¼šæ¨¡å‹æ–‡ä»¶åœ¨ /path/to/vits-zh-aishell3/vits-aishell3.onnx
        // é‚£ä¹ˆ dataDir åº”è¯¥æ˜¯ /path/to/vits-zh-aishell3/
        final actualDataDir = modelFile.parent.path;
        print('ğŸ“‚ å®é™…æ•°æ®ç›®å½•: $actualDataDir');
        
        // æŸ¥æ‰¾ tokens.txt æ–‡ä»¶ï¼ˆé¦–å…ˆåœ¨æ¨¡å‹æ–‡ä»¶åŒç›®å½•æŸ¥æ‰¾ï¼‰
        String? tokensPath;
        final tokensFile = File('$actualDataDir/tokens.txt');
        if (await tokensFile.exists()) {
          tokensPath = tokensFile.path;
          print('âœ… åœ¨æ¨¡å‹ç›®å½•æ‰¾åˆ° tokens.txt: $tokensPath');
        } else {
          // å¦‚æœåœ¨æ¨¡å‹æ–‡ä»¶åŒç›®å½•æ‰¾ä¸åˆ°ï¼Œé€’å½’æœç´¢
          if (_modelDir != null) {
            final dir = Directory(_modelDir!);
            if (await dir.exists()) {
              await for (final entity in dir.list(recursive: true)) {
                if (entity is File && entity.path.toLowerCase().endsWith('tokens.txt')) {
                  tokensPath = entity.path;
                  print('âœ… é€’å½’æ‰¾åˆ° tokens.txt: $tokensPath');
                  break;
                }
              }
            }
          }
        }
        
        // æŸ¥æ‰¾ lexicon.txt æ–‡ä»¶ï¼ˆæŸäº›æ¨¡å‹éœ€è¦ï¼‰
        String? lexiconPath;
        final lexiconFile = File('$actualDataDir/lexicon.txt');
        if (await lexiconFile.exists()) {
          lexiconPath = lexiconFile.path;
          print('âœ… æ‰¾åˆ° lexicon.txt: $lexiconPath');
        }
        
        // æŸ¥æ‰¾ phontab æ–‡ä»¶ï¼ˆæŸäº›æ¨¡å‹å¿…éœ€ï¼‰
        final phontabFile = File('$actualDataDir/phontab');
        final hasPhontab = await phontabFile.exists();
        
        // åˆ—å‡ºæ•°æ®ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        final dataDirObj = Directory(actualDataDir);
        if (await dataDirObj.exists()) {
          print('ğŸ“‚ æ•°æ®ç›®å½•å†…å®¹:');
          await for (final entity in dataDirObj.list()) {
            if (entity is File) {
              final size = await entity.length();
              print('   - ${entity.path.split('/').last} (${size} å­—èŠ‚)');
            } else if (entity is Directory) {
              print('   - ${entity.path.split('/').last}/ (ç›®å½•)');
            }
          }
        }
        
        // æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œvits-zh-aishell3 æ¨¡å‹ä¸éœ€è¦ phontab å’Œ phonindex æ–‡ä»¶
        // è¿™äº›æ–‡ä»¶æ˜¯ espeak-ng çš„ä¸€éƒ¨åˆ†ï¼Œä½†å¯¹äºä¸­æ–‡ VITS æ¨¡å‹ä¸æ˜¯å¿…éœ€çš„
        // å¦‚æœè®¾ç½® dataDirï¼ŒSherpa-ONNX å¯èƒ½ä¼šæ£€æŸ¥è¿™äº›æ–‡ä»¶
        // å°è¯•ä¸è®¾ç½® dataDirï¼Œåªä½¿ç”¨ modelã€tokens å’Œ lexicon
        
        // å°è¯•ç­–ç•¥ï¼šå…ˆä¸è®¾ç½® dataDirï¼Œå¦‚æœå¤±è´¥å†å°è¯•å…¶ä»–æ–¹æ³•
        String dataDirToUse = '';
        
        // æ£€æŸ¥æ¨¡å‹ç›®å½•ä¸­æ˜¯å¦æœ‰ .fst æ–‡ä»¶ï¼ˆè¿™äº›æ˜¯è§„åˆ™æ–‡ä»¶ï¼Œå¯èƒ½éœ€è¦ dataDirï¼‰
        bool hasFstFiles = false;
        if (await dataDirObj.exists()) {
          await for (final entity in dataDirObj.list()) {
            if (entity is File && entity.path.toLowerCase().endsWith('.fst')) {
              hasFstFiles = true;
              break;
            }
          }
        }
        
        // å¦‚æœæœ‰ .fst æ–‡ä»¶ï¼Œå¯èƒ½éœ€è¦ dataDirï¼Œä½†å°è¯•ä½¿ç”¨ç©ºå­—ç¬¦ä¸²
        // å¦‚æœæ¨¡å‹åŒ…ä¸­ç¡®å®éœ€è¦ dataDirï¼Œä¼šåœ¨åˆ›å»ºæ—¶å¤±è´¥ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥å°è¯•å…¶ä»–æ–¹æ³•
        if (hasFstFiles) {
          print('ğŸ“ æ£€æµ‹åˆ° .fst è§„åˆ™æ–‡ä»¶ï¼Œä½†å°è¯•ä¸è®¾ç½® dataDirï¼ˆå®˜æ–¹æ¨¡å‹ä¸éœ€è¦ phontabï¼‰');
          dataDirToUse = ''; // å°è¯•ä¸ä½¿ç”¨ dataDir
        } else {
          dataDirToUse = ''; // ä¸ä½¿ç”¨ dataDir
        }
        
        print('ğŸ“‚ é…ç½® dataDir: ${dataDirToUse.isEmpty ? "(ç©ºï¼Œä¸è®¾ç½®)" : dataDirToUse}');
        
        // åˆ›å»º VITS æ¨¡å‹é…ç½®
        // æ³¨æ„ï¼šæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œvits-zh-aishell3 åªéœ€è¦ modelã€tokens å’Œå¯é€‰çš„ lexicon
        final vitsConfig = OfflineTtsVitsModelConfig(
          model: _modelPath!,
          tokens: tokensPath ?? '', // å¿…é¡»çš„ tokens.txt
          lexicon: lexiconPath ?? '', // å¯é€‰çš„ lexicon.txt
          dataDir: dataDirToUse, // å°è¯•ä¸è®¾ç½® dataDir
        );
        
        print('âš™ï¸  VITS é…ç½®:');
        print('   model: ${vitsConfig.model}');
        print('   tokens: ${vitsConfig.tokens.isEmpty ? "(æœªæ‰¾åˆ°)" : vitsConfig.tokens}');
        print('   lexicon: ${vitsConfig.lexicon.isEmpty ? "(æ— )" : vitsConfig.lexicon}');
        print('   dataDir: ${vitsConfig.dataDir.isEmpty ? "(æ— )" : vitsConfig.dataDir}');
        
        // åˆ›å»ºæ¨¡å‹é…ç½®
        final modelConfig = OfflineTtsModelConfig(
          vits: vitsConfig,
          numThreads: 1,
          debug: true, // å¯ç”¨è°ƒè¯•ä»¥è·å–æ›´å¤šä¿¡æ¯
          provider: 'cpu',
        );
        
        // åˆ›å»º TTS é…ç½®
        final ttsConfig = OfflineTtsConfig(
          model: modelConfig,
        );
        
        // åˆ›å»º TTS å¼•æ“å®ä¾‹
        print('ğŸ”„ æ­£åœ¨åˆ›å»º TTS å¼•æ“...');
        _tts = OfflineTts(ttsConfig);
        
        print('âœ… Sherpa-ONNX TTS å¼•æ“åˆå§‹åŒ–æˆåŠŸ');
        print('   æ¨¡å‹è·¯å¾„: $_modelPath');
        print('   æ¨¡å‹ç›®å½•: $_modelDir');
      } catch (e, stackTrace) {
        print('âš ï¸ Sherpa-ONNX åˆå§‹åŒ–å¤±è´¥: $e');
        print('   å †æ ˆè·Ÿè¸ª: $stackTrace');
        // å¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼Œç»™å‡ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
        if (e.toString().contains('NoSuchMethodError') || 
            e.toString().contains('ClassNotFoundException')) {
          throw Exception(
            'sherpa_onnx æ’ä»¶æœªæ­£ç¡®å®‰è£…æˆ–é…ç½®ã€‚\n'
            'è¯·ç¡®ä¿ï¼š\n'
            '1. å·²è¿è¡Œ flutter pub get å®‰è£…æ’ä»¶\n'
            '2. æ¨¡å‹æ–‡ä»¶å®Œæ•´ä¸”è·¯å¾„æ­£ç¡®\n'
            '3. æ¨¡å‹ç›®å½•åŒ…å«å¿…è¦çš„é…ç½®æ–‡ä»¶ï¼ˆå¦‚ tokens.txtï¼‰\n'
            'é”™è¯¯è¯¦æƒ…: $e'
          );
        }
        throw Exception('Sherpa-ONNX åˆå§‹åŒ–å¤±è´¥: $e');
      }
      
      // åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾å™¨
      _audioPlayer.onPlayerComplete.listen((_) {
        _onPlaybackComplete();
      });
      
      _audioPlayer.onPositionChanged.listen((duration) {
        _onPositionChanged(duration);
      });
      
      _isInitialized = true;
    } catch (e) {
      throw Exception('Sherpa-ONNX åˆå§‹åŒ–å¤±è´¥: $e');
    }
  }

  /// è®¾ç½®å®Œæˆå›è°ƒ
  void setOnComplete(VoidCallback? callback) {
    _onComplete = callback;
  }

  /// è®¾ç½®é”™è¯¯å›è°ƒ
  void setOnError(Function(String)? callback) {
    _onError = callback;
  }

  /// è®¾ç½®è¿›åº¦å›è°ƒ
  void setOnProgress(Function(int, int)? callback) {
    _onProgress = callback;
  }

  /// è®¾ç½®è¯­è¨€
  Future<void> setLanguage(String language) async {
    // Sherpa-ONNX ä½¿ç”¨æ¨¡å‹æ–‡ä»¶æ¥ç¡®å®šè¯­è¨€
  }

  /// è®¾ç½®è¯­é€Ÿ
  Future<void> setSpeechRate(double rate) async {
    _currentRate = rate.clamp(0.5, 2.0);
    // å¦‚æœå·²åˆå§‹åŒ–ï¼Œæ›´æ–°å¼•æ“é€Ÿåº¦
    if (_tts != null && _isInitialized) {
      // æ³¨æ„ï¼šsherpa_onnx æ’ä»¶å¯èƒ½ä¸æ”¯æŒåŠ¨æ€æ›´æ”¹é€Ÿåº¦
      // å¦‚æœéœ€è¦æ›´æ”¹é€Ÿåº¦ï¼Œå¯èƒ½éœ€è¦é‡æ–°åˆå§‹åŒ–å¼•æ“
    }
  }

  /// è®¾ç½®éŸ³é‡
  Future<void> setVolume(double volume) async {
    await _audioPlayer.setVolume(volume);
  }

  /// è®¾ç½®éŸ³è°ƒ
  Future<void> setPitch(double pitch) async {
    // æ³¨æ„ï¼šsherpa-onnx çš„éŸ³è°ƒæ§åˆ¶å¯èƒ½éœ€è¦é€šè¿‡æ¨¡å‹å‚æ•°å®ç°
  }

  /// åˆæˆå¹¶æ’­æ”¾è¯­éŸ³
  Future<void> speak(String text, {int startPosition = 0}) async {
    if (!_isInitialized || _tts == null) {
      await initialize();
    }
    
    if (text.isEmpty) return;
    
    if (_tts == null) {
      throw Exception('TTS å¼•æ“æœªåˆå§‹åŒ–');
    }
    
    _currentText = text;
    
    try {
      // åœæ­¢å½“å‰æ’­æ”¾
      await stop();
      
      // ä½¿ç”¨å®˜æ–¹æ’ä»¶åˆæˆè¯­éŸ³
      print('ğŸ¤ å¼€å§‹åˆæˆè¯­éŸ³: ${text.length} å­—ç¬¦');
      
      try {
        // ä½¿ç”¨ Sherpa-ONNX åˆæˆè¯­éŸ³
        // generate æ–¹æ³•è¿”å› GeneratedAudioï¼ŒåŒ…å« samples (Float32List) å’Œ sampleRate
        final generatedAudio = _tts!.generate(
          text: text,
          sid: 0, // speaker IDï¼Œå¦‚æœæœ‰å¤šä¸ªè¯´è¯äºº
          speed: _currentRate.toDouble(),
        );
        
        if (generatedAudio.samples.isEmpty) {
          throw Exception('è¯­éŸ³åˆæˆå¤±è´¥ï¼šæœªç”ŸæˆéŸ³é¢‘æ•°æ®');
        }
        
        // è·å–é‡‡æ ·ç‡
        final sampleRate = generatedAudio.sampleRate;
        
        // å°† Float32List è½¬æ¢ä¸º 16ä½ PCM å­—èŠ‚æ•°ç»„ï¼ˆlittle-endianï¼‰
        final audioBytes = <int>[];
        for (final sample in generatedAudio.samples) {
          // å°†æµ®ç‚¹æ•°é™åˆ¶åœ¨ -1.0 åˆ° 1.0 ä¹‹é—´ï¼Œç„¶åè½¬æ¢ä¸º 16ä½æ•´æ•°
          final int16Value = (sample.clamp(-1.0, 1.0) * 32767).round();
          // è½¬æ¢ä¸º little-endian å­—èŠ‚
          audioBytes.add(int16Value & 0xFF); // ä½å­—èŠ‚
          audioBytes.add((int16Value >> 8) & 0xFF); // é«˜å­—èŠ‚
        }
        
        // ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
        final audioFile = await _saveAudioToFile(
          audioBytes,
          sampleRate,
        );
        
        // ä¼°ç®—æ€»æ—¶é•¿ï¼ˆåŸºäºéŸ³é¢‘æ ·æœ¬æ•°é‡å’Œé‡‡æ ·ç‡ï¼‰
        final samplesCount = generatedAudio.samples.length;
        _totalDuration = (samplesCount / sampleRate * 1000).round();
        
        // æ’­æ”¾éŸ³é¢‘
        await _playAudio(audioFile, startPosition);
        
        // å¯åŠ¨è¿›åº¦è¿½è¸ª
        _startProgressTracking(startPosition);
        
        print('âœ… è¯­éŸ³åˆæˆå®Œæˆï¼Œæ—¶é•¿: ${_totalDuration}msï¼Œé‡‡æ ·ç‡: ${sampleRate}Hz');
      } catch (e) {
        print('âš ï¸ è¯­éŸ³åˆæˆå¤±è´¥: $e');
        throw Exception('è¯­éŸ³åˆæˆå¤±è´¥: $e');
      }
      
    } catch (e) {
      _onError?.call('è¯­éŸ³åˆæˆå¤±è´¥: $e');
      rethrow;
    }
  }

  /// ä¿å­˜éŸ³é¢‘åˆ°æ–‡ä»¶ï¼ˆWAV æ ¼å¼ï¼‰
  Future<File> _saveAudioToFile(List<int> audioData, int sampleRate) async {
    final tempDir = await getTemporaryDirectory();
    final audioFile = File('${tempDir.path}/tts_${DateTime.now().millisecondsSinceEpoch}.wav');
    
    // åˆ›å»º WAV æ–‡ä»¶å¤´
    final wavHeader = _createWavHeader(audioData.length, sampleRate);
    final wavData = [...wavHeader, ...audioData];
    
    await audioFile.writeAsBytes(wavData);
    return audioFile;
  }

  /// åˆ›å»º WAV æ–‡ä»¶å¤´
  List<int> _createWavHeader(int dataSize, int sampleRate) {
    final header = <int>[];
    
    // RIFF header
    header.addAll('RIFF'.codeUnits);
    header.addAll(_intToBytes(dataSize + 36, 4)); // File size - 8
    header.addAll('WAVE'.codeUnits);
    
    // fmt chunk
    header.addAll('fmt '.codeUnits);
    header.addAll(_intToBytes(16, 4)); // Subchunk1Size
    header.addAll(_intToBytes(1, 2)); // AudioFormat (PCM)
    header.addAll(_intToBytes(1, 2)); // NumChannels (mono)
    header.addAll(_intToBytes(sampleRate, 4)); // SampleRate
    header.addAll(_intToBytes(sampleRate * 2, 4)); // ByteRate
    header.addAll(_intToBytes(2, 2)); // BlockAlign
    header.addAll(_intToBytes(16, 2)); // BitsPerSample
    
    // data chunk
    header.addAll('data'.codeUnits);
    header.addAll(_intToBytes(dataSize, 4)); // Subchunk2Size
    
    return header;
  }

  /// å°†æ•´æ•°è½¬æ¢ä¸ºå­—èŠ‚æ•°ç»„ï¼ˆlittle endianï¼‰
  List<int> _intToBytes(int value, int length) {
    final bytes = <int>[];
    for (int i = 0; i < length; i++) {
      bytes.add(value & 0xFF);
      value >>= 8;
    }
    return bytes;
  }

  /// æ’­æ”¾éŸ³é¢‘
  Future<void> _playAudio(File audioFile, int startPosition) async {
    await _audioPlayer.play(
      DeviceFileSource(audioFile.path),
      position: Duration(milliseconds: startPosition),
    );
  }

  /// å¯åŠ¨è¿›åº¦è¿½è¸ª
  void _startProgressTracking(int startPosition) {
    _stopProgressTracking();
    _currentPosition = startPosition;
    
    if (_totalDuration > 0) {
      _progressTimer = Timer.periodic(const Duration(milliseconds: 250), (timer) {
        _currentPosition += 250;
        
        if (_currentPosition >= _totalDuration) {
          _currentPosition = _totalDuration;
          _stopProgressTracking();
        }
        
        _onProgress?.call(_currentPosition, _totalDuration);
      });
    }
  }

  /// åœæ­¢è¿›åº¦è¿½è¸ª
  void _stopProgressTracking() {
    _progressTimer?.cancel();
    _progressTimer = null;
  }

  /// æ’­æ”¾å®Œæˆå›è°ƒ
  void _onPlaybackComplete() {
    _stopProgressTracking();
    _currentPosition = _totalDuration;
    _onProgress?.call(_currentPosition, _totalDuration);
    _onComplete?.call();
  }

  /// ä½ç½®å˜åŒ–å›è°ƒ
  void _onPositionChanged(Duration position) {
    _currentPosition = position.inMilliseconds;
    _onProgress?.call(_currentPosition, _totalDuration);
  }

  /// åœæ­¢æ’­æ”¾
  Future<void> stop({bool resetPosition = false}) async {
    await _audioPlayer.stop();
    _stopProgressTracking();
    if (resetPosition) {
      _currentPosition = 0;
      _onProgress?.call(0, _totalDuration);
    }
  }

  /// æš‚åœæ’­æ”¾
  Future<void> pause() async {
    await _audioPlayer.pause();
    _stopProgressTracking();
    _onProgress?.call(_currentPosition, _totalDuration);
  }

  /// è·å–å½“å‰æ’­æ”¾ä½ç½®
  int getCurrentPosition() => _currentPosition;

  /// è·å–æ€»æ—¶é•¿
  int getTotalDuration() => _totalDuration;

  /// è·³è½¬åˆ°æŒ‡å®šä½ç½®
  Future<void> seekToPosition(int positionInMs) async {
    await _audioPlayer.seek(Duration(milliseconds: positionInMs));
    _currentPosition = positionInMs;
    _onProgress?.call(_currentPosition, _totalDuration);
  }

  /// åé€€æŒ‡å®šæ¯«ç§’
  Future<void> seekBackward(int milliseconds) async {
    final newPosition = (_currentPosition - milliseconds).clamp(0, _totalDuration);
    await seekToPosition(newPosition);
  }

  /// å‰è¿›æŒ‡å®šæ¯«ç§’
  Future<void> seekForward(int milliseconds) async {
    final newPosition = (_currentPosition + milliseconds).clamp(0, _totalDuration);
    await seekToPosition(newPosition);
  }

  /// æ¸…ç†èµ„æº
  void dispose() {
    _stopProgressTracking();
    if (_tts != null) {
      try {
        // è°ƒç”¨ free() æ–¹æ³•é‡Šæ”¾èµ„æº
        _tts!.free();
        _tts = null;
      } catch (e) {
        print('æ¸…ç† TTS å¼•æ“æ—¶å‡ºé”™: $e');
        _tts = null;
      }
    }
    _audioPlayer.dispose();
    _isInitialized = false;
  }
}
